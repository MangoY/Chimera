{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import math\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import beta\n",
    "import re\n",
    "import random\n",
    "import scipy\n",
    "import pickle\n",
    "\n",
    "# import the Chimera functions\n",
    "from run_hls import get_perf, execute_hls\n",
    "from pareto import getParetoFrontier, checkParetoOptimal, getProbabilityOfEval\n",
    "from generate_directives import RandomDirectiveGenerator, DirectiveCrossover, DirectiveMutator, DirectiveWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row(df, row):\n",
    "    if len(df) == 0:\n",
    "        # return empty if input is empty\n",
    "        return pd.DataFrame()\n",
    "    else:\n",
    "        srs = pd.Series(np.full(len(df), True))\n",
    "        for col in row.keys():\n",
    "            val = row[col]\n",
    "            srs = srs & (df[col] == val)\n",
    "        return df[srs]\n",
    "    \n",
    "def getPopulation(dataset, threshold=1.05, exclude_infeasible=True):\n",
    "    pareto_frontier = getParetoFrontier(dataset, exclude_infeasible=exclude_infeasible)\n",
    "    population = pd.DataFrame(columns=dataset.columns)\n",
    "    for i,row in enumerate(dataset.iloc):\n",
    "        is_near_optimal = checkParetoOptimal(row, pareto_frontier, threshold)\n",
    "        # 3/8 add this, since in some cases infeasible points can also provide useful information\n",
    "        if exclude_infeasible:\n",
    "            is_feasible = row.is_feasible\n",
    "        else:\n",
    "            is_feasible = True\n",
    "        is_error = row.is_error\n",
    "        if(is_near_optimal and is_feasible and (not is_error)):\n",
    "            population = population.append(row)\n",
    "    return population\n",
    "\n",
    "def importanceAnalysis(models, dataset, weights=[1, 0.4, 0.1, 0.1, 0.4]):\n",
    "    ''' \n",
    "        Optional feature\n",
    "        The importance analysis can be added to the flow. It will adjust factor assigned to each\n",
    "        variable based on its importance in the random forest models. In the published version, this feature is not used. This is to be further improved in the\n",
    "        future.\n",
    "        See importanceAdjustment function for more details.\n",
    "    '''\n",
    "    columns = dataset.columns[:-7]\n",
    "    importances_raw = np.zeros_like(regr_lat.feature_importances_)\n",
    "    \n",
    "    for i, regr in enumerate(models):\n",
    "        importances_raw = importances_raw + regr.feature_importances_ * weights[i]\n",
    "    \n",
    "    importances = {}\n",
    "    pos = 0\n",
    "    for i,variable_name in enumerate(columns):\n",
    "        if (re.match('^loop_.+_type$' ,variable_name)):\n",
    "            importances[variable_name] = np.sum(importances_raw[pos:pos+3])/np.sum(weights)\n",
    "            pos = pos + 3\n",
    "        elif (re.match('^loop_.+_factor$' ,variable_name)):\n",
    "            importances[variable_name] = np.sum(importances_raw[pos:pos+1])/np.sum(weights)\n",
    "            pos = pos + 1\n",
    "        elif (re.match('^array_.+_type$' ,variable_name)):\n",
    "            importances[variable_name] = np.sum(importances_raw[pos:pos+3])/np.sum(weights)\n",
    "            pos = pos + 3\n",
    "        elif (re.match('^array_.+_factor$' ,variable_name)):\n",
    "            importances[variable_name] = np.sum(importances_raw[pos:pos+1])/np.sum(weights)\n",
    "            pos = pos + 1\n",
    "    return importances\n",
    "\n",
    "def importanceAdjustment(importances, gamma, prob_scale=1.5):\n",
    "    ''' \n",
    "        Optional feature\n",
    "        The importance analysis can be added to the flow. It will adjust factor assigned to each\n",
    "        variable based on its importance in the random forest models.\n",
    "        The adjustment is based on the overall progress of the exploration progress, during the\n",
    "        initial exploration, more importance will be assigned to factors of greater importance.\n",
    "        So it intends to be a 'coarse' exploration. Whereas, later, larger factors will be \n",
    "        assigned to features with less imporance, which meant to be for 'fine' exploration.\n",
    "        In the published version, this feature is not used. This is to be further improved in the\n",
    "        future.\n",
    "    '''\n",
    "    def getMutationProb(normalized_importance, gamma):\n",
    "        x = gamma\n",
    "        mean = normalized_importance\n",
    "        stdev = 0.3 # let's test fixed stdev first\n",
    "        y = (x - mean)/stdev\n",
    "        return scipy.stats.norm.pdf(y)*np.sqrt(2*np.pi)/2\n",
    "    \n",
    "    adjusted_importances = importances.copy()\n",
    "    params = importances.keys()\n",
    "    vals = list(importances.values())\n",
    "    max_val = np.max(vals)\n",
    "    min_val = np.min(vals)\n",
    "    \n",
    "    for param in params:\n",
    "        importance = float(importances[param])\n",
    "        \n",
    "        # normalized importance\n",
    "        normalized_importance = (importance - min_val)/(max_val - min_val)\n",
    "        \n",
    "        # get adjusted importance/ probability of mutation\n",
    "        # adjusted_importance = getMutationProb(normalized_importance, gamma) * prob_scale\n",
    "        adjusted_importance = 0.1\n",
    "        adjusted_importances.update({param: adjusted_importance})\n",
    "    \n",
    "    return adjusted_importances\n",
    "\n",
    "class BetaDistCounter():\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "        self.a = 1  # the number of times this socket returned a charge        \n",
    "        self.b = 1  # the number of times no charge was returned     \n",
    "    \n",
    "    def reset(self):\n",
    "        self.__init__()\n",
    "    \n",
    "    def update(self,R):\n",
    "        self.n += 1    \n",
    "        self.a += R\n",
    "        self.b += (1-R)\n",
    "        \n",
    "    def sample(self):\n",
    "        return np.random.beta(self.a,self.b)\n",
    "    \n",
    "def selectMethod(method_records, view_boundary=30):\n",
    "    # initialize the beta distributions of them\n",
    "    random_beta = BetaDistCounter()\n",
    "    evo_beta = BetaDistCounter()\n",
    "    mut_beta = BetaDistCounter()\n",
    "    records_in_view = method_records[-view_boundary:]\n",
    "    for method, result in records_in_view:\n",
    "        if(method == 'rand'):\n",
    "            random_beta.update(result)\n",
    "        elif(method == 'evo'):\n",
    "            evo_beta.update(result)\n",
    "        elif(method == 'mut'):\n",
    "            mut_beta.update(result)\n",
    "        else:\n",
    "            raise(AssertionError('Unknown proposing method'))\n",
    "    \n",
    "    rand_beta_sample = random_beta.sample()\n",
    "    evo_beta_sample = evo_beta.sample()\n",
    "    mut_beta_sample = mut_beta.sample()\n",
    "    print('Rand beta sample: '+str(rand_beta_sample))\n",
    "    print('Evo beta sample: '+str(evo_beta_sample))\n",
    "    print('Mut beta sample: '+str(mut_beta_sample))\n",
    "\n",
    "    select = np.argmax([rand_beta_sample, evo_beta_sample, mut_beta_sample])\n",
    "    print([rand_beta_sample, evo_beta_sample, mut_beta_sample])\n",
    "    methods = ['rand', 'evo', 'mut']\n",
    "    print(methods[select])\n",
    "    return methods[select]\n",
    "\n",
    "def predict_perf(parameters, models):\n",
    "    regr_lat, regr_dsp, regr_ff, regr_lut, regr_bram, clss_timeout = models\n",
    "    \n",
    "    encoded_features = preprocessing(pd.Series(parameters).to_frame().T.to_numpy(), feature_columns)\n",
    "\n",
    "    pred_lat = regr_lat.predict(encoded_features)\n",
    "    pred_dsp = regr_dsp.predict(encoded_features)\n",
    "    pred_ff = regr_ff.predict(encoded_features)\n",
    "    pred_lut = regr_lut.predict(encoded_features)\n",
    "    pred_bram = regr_bram.predict(encoded_features)\n",
    "    proba_timeout = clss_timeout.predict_proba(encoded_features)[0,0]\n",
    "\n",
    "    predicted_perf = {'latency':pred_lat,\n",
    "                      'dsp_perc':pred_dsp,\n",
    "                      'ff_perc':pred_ff, \n",
    "                      'lut_perc':pred_lut,\n",
    "                      'bram_perc':pred_bram}\n",
    "    return predicted_perf, proba_timeout\n",
    "\n",
    "def randProposal(directives_path, no_partitioning):\n",
    "    _, parameters = dir_gen.generate_directives(out_file_path=None, no_partitioning=no_partitioning)\n",
    "\n",
    "    return parameters\n",
    "\n",
    "def evoProposal(no_partitioning, importances, gamma, dataset, models, pareto_frontier, n_families=3, n_offsprings=3, threshold=1.0, exclude_infeasible=True):\n",
    "    pareto_set = getPopulation(dataset, threshold=1.0, exclude_infeasible=exclude_infeasible).sort_values('latency')\n",
    "    \n",
    "    # select only 1 point for each unique latency randomly\n",
    "    unique_latencies = pareto_set['latency'].unique()\n",
    "    unique_pareto_points_idx = []\n",
    "    for lat in unique_latencies:\n",
    "        eq_lat_points = pareto_set[pareto_set['latency'] == lat]\n",
    "        rand_idx = random.randint(0, len(eq_lat_points)-1)\n",
    "        selected = eq_lat_points.index[rand_idx]\n",
    "        unique_pareto_points_idx.append(selected)\n",
    "    pareto_points = pareto_set.loc[unique_pareto_points_idx]\n",
    "    \n",
    "    latency = pareto_frontier['latency']\n",
    "    min_lat = min(latency)\n",
    "    max_lat = max(latency)\n",
    "\n",
    "    # get the population\n",
    "    population = getPopulation(dataset, threshold=1.2, exclude_infeasible=exclude_infeasible)\n",
    "\n",
    "    list_params = []\n",
    "    list_probs = []\n",
    "\n",
    "    for i in range(n_families):\n",
    "        parent_idx = np.random.randint(0, len(population),size=1)\n",
    "        parent_rand = population.iloc[parent_idx]\n",
    "        latency_ranking = latency.append(parent_rand['latency'])\n",
    "        ranking = latency_ranking.rank(method='min')\n",
    "        rank = int(ranking.iloc[-1])\n",
    "\n",
    "        parent_lat = parent_rand['latency'].to_numpy()[0]\n",
    "        \n",
    "        if(parent_lat <= min_lat): # unlikely to happen, just in case\n",
    "            print('case 1: selected the fastest')\n",
    "            if(len(pareto_points) == 1): # edge case, only 1 in pareto set\n",
    "                parent_pareto = pareto_points.iloc[0] # other parent is the next fastest one\n",
    "            else:\n",
    "                parent_pareto = pareto_points.iloc[1] # other parent is the next fastest one\n",
    "        elif(parent_lat >= max_lat): # it's worse than the pareto points\n",
    "            print('case 2: selected the slowest')\n",
    "            parent_pareto = pareto_points.iloc[-2] # other parent is the second from the last\n",
    "        else:\n",
    "            print('case 3: selected a middle one')\n",
    "            if(parent_lat in list(latency)): # in this case rank-1 will be the point it self\n",
    "                print('selected does have pareto_latency')\n",
    "                upper = pareto_points.iloc[rank] # neighboring point on the frontier with higher latency\n",
    "                lower = pareto_points.iloc[rank-2] # neighboring point on the frontier with lower latency\n",
    "            else:\n",
    "                print('selected does not have pareto_latency')\n",
    "                upper = pareto_points.iloc[rank-1] # neighboring point on the frontier with higher latency\n",
    "                lower = pareto_points.iloc[rank-2] # neighboring point on the frontier with lower latency\n",
    "            parent_pareto = random.choice([upper, lower])\n",
    "        \n",
    "        # parent_rand is a DF, parent pareto is a series\n",
    "        parents = parent_rand.append(parent_pareto)\n",
    "\n",
    "        for j in range(n_offsprings):\n",
    "            _, offspring_parameters = crossover.generate_directives(out_file_path=None, \n",
    "                                                                    no_partitioning=no_partitioning, \n",
    "                                                                    context=parents)\n",
    "            offspring_perf,_ = predict_perf(offspring_parameters, models)\n",
    "            list_params.append(offspring_parameters)\n",
    "            list_probs.append(getProbabilityOfEval(offspring_perf, pareto_frontier, threshold=threshold))\n",
    "\n",
    "            _, mutant_parameters = mutator.generate_directives(out_file_path=None, \n",
    "                                                        no_partitioning=no_partitioning, \n",
    "                                                        context=(offspring_parameters, importances))\n",
    "            mutant_perf,_ = predict_perf(mutant_parameters, models)\n",
    "            list_params.append(mutant_parameters)\n",
    "            list_probs.append(getProbabilityOfEval(mutant_perf, pareto_frontier, threshold=threshold))\n",
    "            \n",
    "    for i in range(1, len(list_params)+1):\n",
    "        best = np.argsort(list_probs)[-i]\n",
    "        proba_eval = list_probs[best]\n",
    "        parameters = list_params[best]\n",
    "        if (get_row(dataset, parameters).empty): \n",
    "            break\n",
    "    return parameters, proba_eval\n",
    "\n",
    "def mutProposal(no_partitioning, importances, gamma, dataset, models, pareto_frontier, n_mutants=3, threshold=1.2, exclude_infeasible=True):\n",
    "    pareto_set = getPopulation(dataset, threshold=1.0, exclude_infeasible=exclude_infeasible)\n",
    "    \n",
    "    # select only 1 point for each unique latency randomly\n",
    "    unique_latencies = pareto_set['latency'].unique()\n",
    "    unique_pareto_points_idx = []\n",
    "    for lat in unique_latencies:\n",
    "        eq_lat_points = pareto_set[pareto_set['latency'] == lat]\n",
    "        rand_idx = random.randint(0, len(eq_lat_points)-1)\n",
    "        selected = eq_lat_points.index[rand_idx]\n",
    "        unique_pareto_points_idx.append(selected)\n",
    "    pareto_points = pareto_set.loc[unique_pareto_points_idx]\n",
    "\n",
    "    rand_idx = random.randint(0, len(pareto_points)-1)\n",
    "    _, mutant_parameters = mutator.generate_directives(out_file_path=None, \n",
    "                                            no_partitioning=no_partitioning, \n",
    "                                            context=(pareto_points.iloc[rand_idx], importances))\n",
    "    mutant_perf,_ = predict_perf(mutant_parameters, models)\n",
    "    prob_eval = getProbabilityOfEval(mutant_perf, pareto_frontier, threshold=threshold)\n",
    "    return mutant_parameters, prob_eval\n",
    "\n",
    "def update_models(models, dataset):\n",
    "    regr_lat, regr_dsp, regr_ff, regr_lut, regr_bram, clss_timeout = models\n",
    "    \n",
    "    # extract features and labels from the feature set\n",
    "    feature_columns = dataset.columns[:len(dataset.columns)-7]\n",
    "    label_columns = dataset.columns[len(dataset.columns)-7:]\n",
    "    features = dataset[feature_columns].to_numpy()\n",
    "    labels = dataset[label_columns].to_numpy()\n",
    "    features_encoded = preprocessing(features, feature_columns)\n",
    "\n",
    "    # first determine the fesibility and timeout \n",
    "    timeout= labels[:,-1].astype('bool')\n",
    "\n",
    "    lat = labels[:, 0]\n",
    "    dsp_perc = labels[:, 1]\n",
    "    ff_perc = labels[:, 2]\n",
    "    lut_perc = labels[:, 3]\n",
    "    bram_perc = labels[:, 4]\n",
    "\n",
    "    not_timeout = np.logical_not(labels[:,-1].astype('bool'))\n",
    "    \n",
    "    # Notice that the regressions are trained only on points that do not timeout\n",
    "    # Otherwise, these points will disturb the prediction \n",
    "    regr_lat.fit(features_encoded[not_timeout], lat[not_timeout])\n",
    "    regr_dsp.fit(features_encoded[not_timeout], dsp_perc[not_timeout])\n",
    "    regr_ff.fit(features_encoded[not_timeout], ff_perc[not_timeout])\n",
    "    regr_lut.fit(features_encoded[not_timeout], lut_perc[not_timeout])\n",
    "    regr_bram.fit(features_encoded[not_timeout], bram_perc[not_timeout])\n",
    "    \n",
    "    # timeout prediction will be trained on all points\n",
    "    clss_timeout.fit(features_encoded, timeout)\n",
    "\n",
    "def preprocessing(features, columns):\n",
    "    # define the categories and encoders\n",
    "    # the reason to use predefined categories is to avoid special cases, where some of the input features\n",
    "    # only have one category present in the current dataset\n",
    "    loop_directive_types = ['pipeline','unroll','none']\n",
    "    array_directive_types = ['cyclic','block','complete','none']\n",
    "    #enc_loop = OneHotEncoder(categories=[loop_directive_types], drop='first', sparse=False)\n",
    "    #enc_array = OneHotEncoder(categories=[array_directive_types], drop='first', sparse=False)\n",
    "    # for now, we do not drop the category\n",
    "    enc_loop = OneHotEncoder(categories=[loop_directive_types], sparse=False)\n",
    "    enc_array = OneHotEncoder(categories=[array_directive_types], sparse=False)\n",
    "    \n",
    "    #\n",
    "    list_features_encoded = []\n",
    "    #for i in range(features.shape[1]):\n",
    "    for i,col in enumerate(columns):\n",
    "        feature = features[:,i].reshape(1,-1).transpose()\n",
    "        \n",
    "        # detect data type of a feature\n",
    "        if isinstance(feature[0][0], str):\n",
    "            # identify the type of feature\n",
    "            if (re.match('^loop_.+_type$' ,col)):\n",
    "                encoder = enc_loop\n",
    "            elif (re.match('^array_.+_type$' ,col)):\n",
    "                encoder = enc_array\n",
    "            else:\n",
    "                raise AssertionError('unknown directive types')\n",
    "            \n",
    "            # encode the feature\n",
    "            encoded = encoder.fit_transform(feature).astype('int')\n",
    "            list_features_encoded.append(encoded)\n",
    "        else:\n",
    "            list_features_encoded.append(feature)\n",
    "\n",
    "    encoded_features = np.concatenate(list_features_encoded, axis=1)\n",
    "    return encoded_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block sets the input constants for the exploration\n",
    "# The following is the example configuration for the 3d rendering benchmark\n",
    "parameter_file = './config_files/3dr_params.csv'\n",
    "\n",
    "# path of the directive file to be used\n",
    "# this file is to be generated for each exploration iteration\n",
    "directives_path = './config_files/3dr_directives.tcl'\n",
    "\n",
    "# template file is the template of the TCL script for the vivado HLS project\n",
    "# notice that the path to the source files of the project should also be in\n",
    "# this template file\n",
    "template_path = './config_files/3dr_template.txt'\n",
    "\n",
    "# the name of the top function of the HLS proj\n",
    "top_function = 'rendering'\n",
    "\n",
    "# the FPGA/SoC part name for synthesis\n",
    "part='xc7z045-ffg900-2'\n",
    "\n",
    "# number of samples in the initial exploration process\n",
    "num_initial = 20\n",
    "\n",
    "# number of exploration steps after the initial exploration\n",
    "total_steps = 150\n",
    "\n",
    "# if we want to ignore exploration on the partitioning factors\n",
    "# this is needed for designs that are explicitly pipelined\n",
    "# in such a case no partition should be used. e.g. 3D Rendering\n",
    "no_partitioning = True\n",
    "\n",
    "# \n",
    "ESCAPE_THRESHOLD = 1000 # after 1000 failed attempt to get a point worth evaluating, escape\n",
    "N_OFFSPRING = 20\n",
    "step = 4\n",
    "\n",
    "# initialize the list that stores the exploration method selected for each step of exploration\n",
    "method_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the random directive generators'\n",
    "# see \n",
    "dir_gen = RandomDirectiveGenerator(parameter_file)\n",
    "crossover = DirectiveCrossover(parameter_file)\n",
    "mutator = DirectiveMutator(parameter_file)\n",
    "writer = DirectiveWriter(parameter_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the empty dataframe\n",
    "dataframe_columns = []\n",
    "tunable_params = pd.read_csv(parameter_file)\n",
    "list_columns = []\n",
    "for i in range(len(tunable_params)):\n",
    "    knob = tunable_params.iloc[i]\n",
    "    name=knob['name']\n",
    "    boundary = knob['range']\n",
    "    dim = knob.at['dim']\n",
    "    \n",
    "    # to fix the NaN problem for dim, since dim doesn't exist for loops\n",
    "    try:\n",
    "        knob.at['dim']=int(dim)\n",
    "    except ValueError:\n",
    "        knob.at['dim']=int(0)\n",
    "    \n",
    "    # parse the file and find the column names, the naming MUST be consistent with generate_directives.py\n",
    "    if(knob['type'] == 'loop'):\n",
    "        list_columns.append('loop_'+name+'_type')\n",
    "        list_columns.append('loop_'+name+'_factor')\n",
    "    elif(knob['type'] == 'array'):\n",
    "        if not no_partitioning:\n",
    "            name=name+'_dim'+str(int(dim))\n",
    "            list_columns.append('array_'+name+'_type')\n",
    "            list_columns.append('array_'+name+'_factor')\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        raise AssertionError('Unknow knob type')\n",
    "        \n",
    "# add the columns for HLS result\n",
    "list_columns = list_columns+['latency', 'dsp_perc', 'ff_perc', 'lut_perc', 'bram_perc', 'is_feasible', 'is_error']\n",
    "\n",
    "# initialize the datset to be empty (always)\n",
    "dataset = pd.DataFrame(columns=list_columns)\n",
    "\n",
    "# set the feature columns and label columns\n",
    "feature_columns = dataset.columns[:len(dataset.columns)-7]\n",
    "label_columns = dataset.columns[len(dataset.columns)-7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the folloing code block is for generating the intial random samples\n",
    "# generate random values\n",
    "# 1: initialization phase\n",
    "for i in range(num_initial):\n",
    "    print('Generate design points: {0}/{1}'.format(i, num_initial ))\n",
    "    # generate a new design point that doesn't exist in the dataset0 \n",
    "    while (True):\n",
    "        # generate a new design point\n",
    "        _, parameters = dir_gen.generate_directives(out_file_path=directives_path, no_partitioning=no_partitioning)\n",
    "        \n",
    "        # check if the design point is valid\n",
    "        if (get_row(dataset, parameters).empty): \n",
    "            break\n",
    "    \n",
    "    print(parameters)\n",
    "    \n",
    "    # evaluate the design point\n",
    "    new_design_point = get_perf(\n",
    "                        template_path,  \n",
    "                        directives_path, \n",
    "                        top_function, \n",
    "                        part, \n",
    "                        parameters, \n",
    "                        verbose=False,\n",
    "                        timelimit=600)\n",
    "\n",
    "    print(new_design_point)\n",
    "    #new_design_point = pd.DataFrame.from_dict(parameters, orient='columns')\n",
    "\n",
    "    # add the evaluated design point to current dataset\n",
    "    dataset = dataset.append(new_design_point, ignore_index=True)\n",
    "    #dataset = dataset.append(parameters, ignore_index=True)\n",
    "    dataset.to_csv('3dr_init.csv')\n",
    "    \n",
    "# make sure the is_error column is boolean type\n",
    "dataset.is_error = dataset.is_error.astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./3dr_init.csv', index_col=0)[0:num_init]\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the predictive models\n",
    "regr_lat = RandomForestRegressor(random_state=42)\n",
    "regr_dsp = RandomForestRegressor(random_state=42)\n",
    "regr_ff = RandomForestRegressor(random_state=42)\n",
    "regr_lut = RandomForestRegressor(random_state=42)\n",
    "regr_bram = RandomForestRegressor(random_state=42)\n",
    "clss_timeout = RandomForestClassifier(random_state=42)\n",
    "models = [regr_lat, regr_dsp, regr_ff, regr_lut, regr_bram, clss_timeout]\n",
    "\n",
    "# train the models\n",
    "update_models(models, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pareto_frontier = getParetoFrontier(dataset, exclude_infeasible=True)\n",
    "\n",
    "# define a global step for easier management\n",
    "\n",
    "while True:\n",
    "    print('Globa step: '+str(step))\n",
    "\n",
    "    # select a point proposal method based on beta distribution\n",
    "    method = selectMethod(method_records, view_boundary=30)\n",
    "\n",
    "    if method == 'rand':\n",
    "        print('Method: Random')\n",
    "    elif method == 'evo':\n",
    "        print('Method: Evolution')\n",
    "    elif method == 'mut':\n",
    "        print('Method: Mutation')\n",
    "    else:\n",
    "        raise(AssertionError('Unknown proposing method'))\n",
    "\n",
    "    # gamma value go from 1 to 0\n",
    "    gamma = min(1 - step / (total_steps), 1)\n",
    "    print('Gamma: '+str(gamma))\n",
    "\n",
    "    # importance analyis\n",
    "    importances = importanceAnalysis([regr_lat, regr_dsp, regr_ff, regr_lut, regr_bram], dataset)\n",
    "\n",
    "    # adjust the importances for better exploration\n",
    "    adjusted_importances = importanceAdjustment(importances, gamma)\n",
    "\n",
    "    # set a counter to detect if we are stuck and cannot find a good value\n",
    "    escape_count = 0\n",
    "\n",
    "    while (True):\n",
    "        '''generate a new design point'''\n",
    "        if method == 'rand':\n",
    "            parameters = randProposal(directives_path, no_partitioning)\n",
    "\n",
    "            # make predictions on the performance\n",
    "            predicted_perf, _ = predict_perf(parameters, models)\n",
    "\n",
    "            # calculate the probability of evaluating the point, based on it's quality (how close it is to the Pareto curve)\n",
    "            # 1.5 seems to be a good value, however, 1.5 is also quite wide\n",
    "            proba_eval = getProbabilityOfEval(predicted_perf, pareto_frontier, threshold=1.5)\n",
    "        elif method == 'evo':\n",
    "            parameters, proba_eval = evoProposal(no_partitioning, adjusted_importances, gamma, dataset, models, pareto_frontier)\n",
    "        elif method == 'mut':\n",
    "            parameters, proba_eval = mutProposal(no_partitioning, adjusted_importances, gamma, dataset, models, pareto_frontier)\n",
    "        else:\n",
    "            raise(AssertionError, 'None method selected')\n",
    "\n",
    "        # make predictions on the performance\n",
    "        predicted_perf, proba_timeout = predict_perf(parameters, models)\n",
    "\n",
    "        # increment the escape count\n",
    "        escape_count = escape_count + 1\n",
    "\n",
    "        random_val = np.random.rand(1)[0]\n",
    "        proba_total = proba_eval*proba_timeout\n",
    "        print(predicted_perf)\n",
    "        print('Design:')\n",
    "        print(parameters)\n",
    "        print('random value:'+str(random_val))\n",
    "        print('probability from pareto: '+str(proba_eval))\n",
    "        print('probability from timeout:'+str(proba_timeout))\n",
    "        print('total probability of evaluation:'+str(proba_total))\n",
    "\n",
    "        if ((random_val < proba_total) \\\n",
    "            and get_row(dataset, parameters).empty) \\\n",
    "            or escape_count > 1000:\n",
    "                if(escape_count > 1000): \n",
    "                    print('escape!!')\n",
    "                else: \n",
    "                    print('New design point found.')\n",
    "                break\n",
    "                \n",
    "    # print out the parameters of the design point\n",
    "    print(parameters)\n",
    "    \n",
    "    # output the directives\n",
    "    writer.generate_directives(out_file_path=directives_path, no_partitioning=no_partitioning,context=parameters)\n",
    "\n",
    "    # evaluate the design point\n",
    "    new_design_point = get_perf(template_path, \n",
    "                                directives_path, \n",
    "                                top_function, \n",
    "                                part, \n",
    "                                parameters, \n",
    "                                verbose=False,\n",
    "                                timelimit=800)\n",
    "    \n",
    "    # print out a new design point to be explored\n",
    "    print(new_design_point)\n",
    "\n",
    "    is_pareto_optimal = checkParetoOptimal(new_design_point, pareto_frontier, threshold=1.0)\n",
    "    \n",
    "    # check if it's already an existing cost+latency combination\n",
    "    # if so it's not pareto optimal, this will eliminate some bias on mutation and evo\n",
    "    # gives random more space \n",
    "    latency = new_design_point['latency']\n",
    "    cost = 0.4*new_design_point['dsp_perc'] \\\n",
    "        +0.1*new_design_point['ff_perc'] \\\n",
    "        +0.1*new_design_point['lut_perc'] \\\n",
    "        +0.4*new_design_point['bram_perc']\n",
    "    existing_point = pareto_frontier[(pareto_frontier['latency'] == latency) & (pareto_frontier['cost'] == cost)]\n",
    "    if (len(existing_point) != 0):\n",
    "        print('Existing pareto point!')\n",
    "        is_pareto_optimal = False\n",
    "    \n",
    "    if(is_pareto_optimal):\n",
    "        method_records.append((method, 1))\n",
    "        print('//////////////////////////////////////////////////////')\n",
    "        print('!!!!!!!!!!!!!!!Success: New Pareto Point!!!!!!!!!!!!!!')\n",
    "        print('//////////////////////////////////////////////////////')\n",
    "    else:\n",
    "        method_records.append((method, 0))\n",
    "        print('//////////////////////////////////////////////////////')\n",
    "        print('$$$$$$$$$$$$$$$Fail: BAD BAD BAD Point$$$$$$$$$$$$$$$$')\n",
    "        print('//////////////////////////////////////////////////////')\n",
    "\n",
    "    # add the evaluated design point to current dataset\n",
    "    dataset = dataset.append(new_design_point, ignore_index=True)\n",
    "\n",
    "    # update pareto frontier after getting a new point\n",
    "    pareto_frontier = getParetoFrontier(dataset, exclude_infeasible=True)\n",
    "    print('New Pareto Frontier:')\n",
    "    print(pareto_frontier)\n",
    "\n",
    "    # save data instantly for easier test running\n",
    "    dataset.to_csv('3dr_explored.csv')\n",
    "    pareto_frontier.to_csv('3dr_explored_pareto.csv')\n",
    "    \n",
    "    # increment the global step\n",
    "    step = step + 1\n",
    "\n",
    "    # train the models\n",
    "    update_models(models, dataset)\n",
    "    \n",
    "    # record the explroation method selected for each step in a pickle file\n",
    "    with open('3dr_method_records.pickle', 'wb') as f:\n",
    "        pickle.dump(method_records, f)\n",
    "\n",
    "    # break if needed\n",
    "    if step >= total_steps: break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
